{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Βήμα 0 - Εξοικείωση με Kaggle kernels","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport librosa.display as display\nimport matplotlib.pyplot as plt\n\n#for dirname, _, filenames in os.walk('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/test'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n      \nfiles = os.listdir(\"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/\")\nprint(files)\n#print(np.load('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/test/3431.fused.full.npy'))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:45:14.577122Z","iopub.execute_input":"2022-02-20T19:45:14.577909Z","iopub.status.idle":"2022-02-20T19:45:16.611547Z","shell.execute_reply.started":"2022-02-20T19:45:14.577759Z","shell.execute_reply":"2022-02-20T19:45:16.610658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bήμα 1 - Εξοικείωση με φασματογραφήματα στην κλίμακα mel\n","metadata":{}},{"cell_type":"markdown","source":"# Βήμα 1(α)","metadata":{}},{"cell_type":"code","source":"path = \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt\"\nwith open(path) as f:\n    files = f.readlines()\n    \nfiles.pop(0)\n\nlabel = ''\ncounter = 0\nids = 2*[0]\n\nfor i in range(len(files)):\n    files[i] = files[i].split()\n    if label != files[i][1] and counter < 2:\n        print(files[i])\n        label = files[i][1]\n        ids[counter] = i\n        counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:43:00.342575Z","iopub.execute_input":"2022-02-20T11:43:00.342858Z","iopub.status.idle":"2022-02-20T11:43:00.35781Z","shell.execute_reply.started":"2022-02-20T11:43:00.342828Z","shell.execute_reply":"2022-02-20T11:43:00.357037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 1 (β)","metadata":{}},{"cell_type":"code","source":"spectrogram_file = \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/\"\n\nf = os.listdir(spectrogram_file)\nnew_ids = 2*[0]\nfor i in range(len(f)):\n    if (f[i] == files[ids[0]][0][:-3]):\n        new_ids[0] = i\n    elif (f[i] == files[ids[1]][0][:-3]):\n        new_ids[1] = i","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:43:02.758878Z","iopub.execute_input":"2022-02-20T11:43:02.759461Z","iopub.status.idle":"2022-02-20T11:43:02.960815Z","shell.execute_reply.started":"2022-02-20T11:43:02.75942Z","shell.execute_reply":"2022-02-20T11:43:02.959979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 1 (γ) ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n\nspectrograms1 = np.load(spectrogram_file + f[new_ids[0]])\nmel_spectrogram1 = spectrograms1[:128]\nchromagram1 = spectrograms1[128:]\ndisplay.specshow(mel_spectrogram1, x_axis = 'time', y_axis = 'mel', ax = ax[0])\nax[0].set(title = 'Spectrogram of a sample with label: {}'.format(files[ids[0]][1]))\nax[0].label_outer()\n\nspectrograms2 = np.load(spectrogram_file + f[new_ids[1]])\nmel_spectrogram2 = spectrograms2[:128]\nchromagram2 = spectrograms2[128:]\ndisplay.specshow(mel_spectrogram2, x_axis = 'time', y_axis = 'mel', ax = ax[1])\nax[1].set(title = 'Spectrogram of a sample with label: {}'.format(files[ids[1]][1]))\nax[1].label_outer()\n\nprint(mel_spectrogram1.shape, mel_spectrogram2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:43:05.644756Z","iopub.execute_input":"2022-02-20T11:43:05.645398Z","iopub.status.idle":"2022-02-20T11:43:06.261441Z","shell.execute_reply.started":"2022-02-20T11:43:05.645354Z","shell.execute_reply":"2022-02-20T11:43:06.260832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 2 - Συγχρονισμός φασματογραφημάτων στο ρυθμό της μουσικής (beat-synced spectrograms)\n","metadata":{}},{"cell_type":"code","source":"spec_beat_file = \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/\"\n\nf = os.listdir(spec_beat_file)\nfig, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n\nbeat_spectrograms1 = np.load(spec_beat_file + f[new_ids[0]])\nbeat_mel_spectrogram1 = beat_spectrograms1[:128]\nbeat_chromagram1 = beat_spectrograms1[128:]\ndisplay.specshow(beat_mel_spectrogram1, x_axis = 'time', y_axis = 'mel', ax = ax[0])\nax[0].set(title = 'Beat-synced spectrogram of a sample with label: {}'.format(files[ids[0]][1]))\nax[0].label_outer()\n\nbeat_spectrograms2 = np.load(spec_beat_file + f[new_ids[1]])\nbeat_mel_spectrogram2 = beat_spectrograms2[:128]\nbeat_chromagram2 = beat_spectrograms2[128:]\ndisplay.specshow(beat_mel_spectrogram2, x_axis = 'time', y_axis = 'mel', ax = ax[1])\nax[1].set(title = 'Beat-synced spectrogram of a sample with label: {}'.format(files[ids[1]][1]))\nax[1].label_outer()\n\nprint(beat_mel_spectrogram1.shape, beat_mel_spectrogram2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:43:12.755949Z","iopub.execute_input":"2022-02-20T11:43:12.756632Z","iopub.status.idle":"2022-02-20T11:43:13.46728Z","shell.execute_reply.started":"2022-02-20T11:43:12.756595Z","shell.execute_reply":"2022-02-20T11:43:13.466652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 3 - Εξοικείωση με χρωμογραφήματα","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True)\n\ndisplay.specshow(chromagram1, x_axis = 'time', y_axis = 'chroma', ax = ax[0][0])\nax[0][0].set(title = 'Chromagram (left) and Beat-synced chromagram (right) of a sample with label: {}'.format(files[ids[0]][1]))\nax[0][0].label_outer()\n\ndisplay.specshow(beat_chromagram1, x_axis = 'time', y_axis = 'chroma', ax = ax[0][1])\n\ndisplay.specshow(chromagram2, x_axis = 'time', y_axis = 'chroma', ax = ax[1][0])\nax[1][0].set(title = 'Chromagram (left) and Beat-synced chromagram (right) of a sample with label: {}'.format(files[ids[1]][1]))\nax[1][0].label_outer()\n\ndisplay.specshow(beat_chromagram2, x_axis = 'time', y_axis = 'chroma', ax = ax[1][1])\n\nprint(chromagram1.shape, chromagram2.shape)\nprint(beat_chromagram1.shape, beat_chromagram2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:43:15.97449Z","iopub.execute_input":"2022-02-20T11:43:15.974749Z","iopub.status.idle":"2022-02-20T11:43:17.07579Z","shell.execute_reply.started":"2022-02-20T11:43:15.974719Z","shell.execute_reply":"2022-02-20T11:43:17.074971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 4 - Φόρτωση και ανάλυση δεδομένων","metadata":{}},{"cell_type":"code","source":"import copy\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n\nCLASS_MAPPING = {\n    \"Rock\": \"Rock\",\n    \"Psych-Rock\": \"Rock\",\n    \"Indie-Rock\": None,\n    \"Post-Rock\": \"Rock\",\n    \"Psych-Folk\": \"Folk\",\n    \"Folk\": \"Folk\",\n    \"Metal\": \"Metal\",\n    \"Punk\": \"Metal\",\n    \"Post-Punk\": None,\n    \"Trip-Hop\": \"Trip-Hop\",\n    \"Pop\": \"Pop\",\n    \"Electronic\": \"Electronic\",\n    \"Hip-Hop\": \"Hip-Hop\",\n    \"Classical\": \"Classical\",\n    \"Blues\": \"Blues\",\n    \"Chiptune\": \"Electronic\",\n    \"Jazz\": \"Jazz\",\n    \"Soundtrack\": None,\n    \"International\": None,\n    \"Old-Time\": None,\n}\n\n\ndef torch_train_val_split(dataset, batch_train, batch_eval,\n                          val_size=0.2, shuffle=True, seed=420):\n    \n    # Creating data indices for training and validation splits:\n        \n    dataset_size = len(dataset)\n    indices = list(range(dataset_size))\n    val_split = int(np.floor(val_size * dataset_size))\n    if shuffle:\n        np.random.seed(seed)\n        np.random.shuffle(indices)\n    train_indices = indices[val_split:]\n    val_indices = indices[:val_split]\n\n    # Creating PT data samplers and loaders:\n        \n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n\n    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n    return train_loader, val_loader\n\ndef read_spectrogram(spectrogram_file,option, chroma=True):\n    # with open(spectrogram_file, \"r\") as f:\n    if(option == 'sp_only'):\n        spectrograms = np.load(spectrogram_file)[:128]\n        \n    elif(option == 'chr_only'):\n        spectrograms = np.load(spectrogram_file)[128:]\n    \n    else:   \n        spectrograms = np.load(spectrogram_file)\n    \n    # spectrograms contains a fused mel spectrogram and chromagram\n    # Decompose as follows\n    \n    return spectrograms.T\n\nclass LabelTransformer(LabelEncoder):\n    def inverse(self, y):\n        try:\n            return super(LabelTransformer, self).inverse_transform(y)\n        except:\n            return super(LabelTransformer, self).inverse_transform([y])\n\n    def transform(self, y):\n        try:\n            return super(LabelTransformer, self).transform(y)\n        except:\n            return super(LabelTransformer, self).transform([y])\n\n\nclass PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[: self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1\n        \nclass SpectrogramDataset(Dataset):\n    def __init__(self, path, option, class_mapping, \n                 train=True, max_length=-1, regression=None):\n        \n        t = \"train\" if train else \"test\"\n        p = os.path.join(path, t)\n        self.regression = regression\n\n        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n        self.files, labels = self.get_files_labels(self.index, class_mapping)\n        self.feats = [read_spectrogram(os.path.join(p, f),option) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n        self.label_transformer = LabelTransformer()\n        \n        if isinstance(labels, (list, tuple)):\n            if not regression:\n                self.labels = np.array(\n                    self.label_transformer.fit_transform(labels)\n                ).astype(\"int64\")\n            else:\n                self.labels = np.array(labels).astype(\"float64\")\n\n    def get_files_labels(self, txt, class_mapping):\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n        files, labels = [], []\n        for l in lines:\n            label = l[1]\n            if class_mapping:\n                label = class_mapping[l[1]]\n            if not label:\n                continue\n            # Kaggle automatically unzips the npy.gz format so this hack is needed\n            _id = l[0].split('.')[0]\n            npy_file = '{}.fused.full.npy'.format(_id)\n            files.append(npy_file)\n            labels.append(label)\n        return files, labels\n\n    def __getitem__(self, item):\n        length = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n\n    def __len__(self):\n        return len(self.labels)\n\nif __name__ == \"__main__\":\n    dataset = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms\",\n        class_mapping=CLASS_MAPPING, train=True,option = 'both')\n\n    print(dataset[10])\n    print(f\"Input: {dataset[10][0].shape}\")\n    print(f\"Label: {dataset[10][1]}\")\n    print(f\"Original length: {dataset[10][2]}\")\n    print(len(dataset))\n    \nclasses_before = [\"Rock\", \"Psych-Rock\", \"Indie-Rock\", \"Post-Rock\",\n                  \"Psych-Folk\", \"Folk\", \"Metal\", \"Punk\", \"Post-Punk\", \n                  \"Trip-Hop\", \"Pop\", \"Electronic\", \"Hip-Hop\", \"Classical\", \n                  \"Blues\", \"Chiptune\", \"Jazz\", \"Soundtrack\", \"International\", \"Old-Time\"]\n\nclasses_after = [\"Rock\", \"Folk\", \"Metal\", \"Trip-Hop\", \"Pop\", \n                 \"Electronic\", \"Hip-Hop\", \"Classical\", \"Blues\", \"Jazz\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:45:26.810481Z","iopub.execute_input":"2022-02-20T19:45:26.810766Z","iopub.status.idle":"2022-02-20T19:46:09.635733Z","shell.execute_reply.started":"2022-02-20T19:45:26.81073Z","shell.execute_reply":"2022-02-20T19:46:09.634597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"before_class_maping = []\nafter_class_maping = []\n\nfor file in files:\n    for i in range (20):\n        if file[1] == classes_before[i]:\n            before_class_maping.append(classes_before[i])\n            break\n            \n    if i == 0 or i == 1 or i == 3:\n        after_class_maping.append(\"Rock\")\n    elif i == 4 or i == 5:\n        after_class_maping.append(\"Folk\")\n    elif i == 6 or i == 7:\n        after_class_maping.append(\"Metal\")\n    elif i == 9:\n        after_class_maping.append(\"Trip-Hop\")\n    elif i == 10:\n        after_class_maping.append(\"Pop\")\n    elif i == 11 or i == 15:\n        after_class_maping.append(\"Electronic\")\n    elif i == 12:\n        after_class_maping.append(\"Hip-Hop\")\n    elif i == 13:\n        after_class_maping.append(\"Classical\")\n    elif i == 14:\n        after_class_maping.append(\"Blues\")\n    elif i == 16:\n        after_class_maping.append(\"Jazz\")\n\n \nfrom collections import Counter\nimport pandas\nletter_counts1 = Counter(before_class_maping)\ndf = pandas.DataFrame.from_dict(letter_counts1, orient='index')\ndf.plot(kind='bar')\n\nletter_counts2 = Counter(after_class_maping)\ndf = pandas.DataFrame.from_dict(letter_counts2, orient='index')\ndf.plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T10:42:06.428618Z","iopub.execute_input":"2022-02-19T10:42:06.429366Z","iopub.status.idle":"2022-02-19T10:42:07.072168Z","shell.execute_reply.started":"2022-02-19T10:42:06.429308Z","shell.execute_reply":"2022-02-19T10:42:07.071496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 5 - Αναγνώριση μουσικού είδους με LSTM\n","metadata":{}},{"cell_type":"markdown","source":"# Δημιουργία του LSTM μοντέλου","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport pickle\nimport torch.optim as optim\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:22.932811Z","iopub.execute_input":"2022-02-20T19:47:22.933738Z","iopub.status.idle":"2022-02-20T19:47:22.939074Z","shell.execute_reply.started":"2022-02-20T19:47:22.933692Z","shell.execute_reply":"2022-02-20T19:47:22.937935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicLSTM(nn.Module):\n    def __init__(self, input_dim, rnn_size, output_dim, num_layers,dropout,bidirectional):\n        super(BasicLSTM, self).__init__()\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n        self.num_layers = num_layers\n        self.rnn_size = rnn_size \n        # Initialize the LSTM, Dropout, Output layers\n        \n        self.lstm = nn.LSTM(input_dim,rnn_size,num_layers,batch_first= True,\n                            bidirectional = self.bidirectional)\n        \n        if(self.bidirectional == True):\n            self.con = 2 \n        else:\n            self.con = 1\n            \n        self.fc = nn.Linear(self.con * rnn_size , output_dim)\n        \n    def forward(self, x, lengths):\n        \"\"\" \n            x : 3D numpy array of dimension N x L x D\n                N: batch index\n                L: sequence index\n                D: feature index\n            lengths: N x 1\n         \"\"\"\n\n        # You must have all of the outputs of the LSTM, but you \n        # need only the last one (that does not exceed the sequence length)\n        # To get it use the last_timestep method\n        # Then pass it through the remaining network\n        \n        x = x.double()\n        h0 = torch.zeros(self.con* self.num_layers,x.size(0),self.rnn_size).to(device)\n        c0 = torch.zeros(self.con* self.num_layers,x.size(0),self.rnn_size).to(device)\n        h0 = h0.double()\n        c0 = c0.double()\n        out, _ = self.lstm(x,(h0,c0))\n        \n        if(self.dropout == 1):\n            drop = nn.Dropout(0.25)\n            out = drop(out)\n            \n        out = self.fc(out)\n            \n        last_outputs = self.last_timestep(out,lengths,self.bidirectional)\n\n        return last_outputs\n\n    def last_timestep(self, outputs, lengths, bidirectional):\n        \"\"\"\n            Returns the last output of the LSTM taking into account the zero padding\n        \"\"\"\n        if bidirectional:\n            forward, backward = self.split_directions(outputs)\n            last_forward = self.last_by_index(forward, lengths)\n            last_backward = backward[:, 0, :]\n            # Concatenate and return - maybe add more functionalities like average\n            return torch.cat((last_forward, last_backward), dim=-1)\n\n        else:\n            return self.last_by_index(outputs, lengths)\n\n    @staticmethod\n    def split_directions(outputs):\n        direction_size = int(outputs.size(-1) / 2)\n        forward = outputs[:, :, :direction_size]\n        backward = outputs[:, :, direction_size:]\n        return forward, backward\n\n    @staticmethod\n    def last_by_index(outputs, lengths):\n        # Index of the last output for each sequence.\n        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n                                               outputs.size(2)).unsqueeze(1)\n        return outputs.gather(1, idx).squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:25.11442Z","iopub.execute_input":"2022-02-20T19:47:25.11526Z","iopub.status.idle":"2022-02-20T19:47:25.142914Z","shell.execute_reply.started":"2022-02-20T19:47:25.11521Z","shell.execute_reply":"2022-02-20T19:47:25.141912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση του LSTM","metadata":{}},{"cell_type":"code","source":"def train_lstm(train_loader,val_loader,output_dim,input_size,lf,filename,overfit_batch=False):\n    \n    input_dim = input_size\n    num_layers = 3\n    rnn_size = 100\n    dropout = 0\n    bidirectional = True\n    patience = 10\n    \n    if(lf == 1):\n        criterion = nn.CrossEntropyLoss()\n    \n    elif (lf == 0):\n        criterion = nn.MSELoss()\n    \n    model = BasicLSTM(input_dim,rnn_size,output_dim,num_layers,dropout,bidirectional).to(device)\n    learning_rate = 1e-4  # the ETA variable in gradient descent\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    loss_per_epoch = []\n    val_loss_per_epoch = []\n    \n    model.train()\n    model = model.double()\n    \n    if(overfit_batch == False):\n        EPOCHS = 50\n        for epoch in range(EPOCHS):\n            val_loss = 0\n            for (i,data) in enumerate(val_loader):\n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n                out = model(X_batch,len_batch).double() # forward pass\n                if(lf == 0 ):\n                    new_shape = (len(y_batch), 1)\n                    y_batch = y_batch.view(new_shape)\n                loss = criterion(out, y_batch) # compute per batch loss \n                val_loss +=loss.detach().item()\n            \n            val_loss_per_epoch.append(val_loss/i)\n            i = np.argmin(val_loss_per_epoch)\n            if (i == epoch):\n                best_model = model   \n            if (epoch > i + patience):\n                val_loss_per_epoch.pop(-1)\n                print('Early stopping...')\n                break\n                \n            running_average_loss = 0\n            for (i,data) in enumerate(train_loader):\n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n            \n                optimizer.zero_grad() # ALWAYS USE THIS!! \n                out = model(X_batch,len_batch).double() # forward pass\n                \n                if( lf == 0 ):\n                    new_shape = (len(y_batch), 1)\n                    y_batch = y_batch.view(new_shape)\n                \n                loss = criterion(out, y_batch) # compute per batch loss \n                loss.backward() # compure gradients based on the loss function\n                optimizer.step() # update weights \n                l = loss.detach().item()\n                running_average_loss += l\n                \n                if i % 10 == 0:\n                    print(\"Epoch: {} \\t Batch: {} \\t Loss {}\".format(epoch, i,\n                                        float(l)))\n                \n            running_average_loss = running_average_loss/(i+1)\n            loss_per_epoch.append(running_average_loss)\n    \n    elif (overfit_batch == True):\n        EPOCHS = 750\n        X_batch , y_batch , len_batch = next(iter(train_loader))\n        for epoch in range(EPOCHS):\n            running_average_loss = 0\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            len_batch = len_batch.to(device)\n            \n            optimizer.zero_grad() # ALWAYS USE THIS!! \n            out = model(X_batch,len_batch).double() # forward pass\n            loss = criterion(out, y_batch) # compute per batch loss \n            loss.backward() # compure gradients based on the loss function\n            optimizer.step() # update weights \n            l = loss.detach().item()\n            running_average_loss += l\n            print(\"Epoch: {} \\t Loss {}\".format(epoch,\n                                      float(l)))\n                \n            running_average_loss = running_average_loss\n            loss_per_epoch.append(running_average_loss)\n            \n    pickle.dump(best_model, open(filename, 'wb'))    \n    return loss_per_epoch,val_loss_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:28.219656Z","iopub.execute_input":"2022-02-20T19:47:28.219978Z","iopub.status.idle":"2022-02-20T19:47:28.239655Z","shell.execute_reply.started":"2022-02-20T19:47:28.219938Z","shell.execute_reply":"2022-02-20T19:47:28.238843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Validation Loss and Loss per Epoch","metadata":{}},{"cell_type":"code","source":"def plot_loss(loss_per_epoch,val_loss_per_epoch, overfit_batch):\n\n    epochs = np.arange(0,len(loss_per_epoch),1)\n    \n    if(overfit_batch == False):\n        plt.plot(epochs,loss_per_epoch,label = 'training loss')\n        plt.plot(epochs,val_loss_per_epoch,label = 'validation loss')\n        plt.grid()\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss Value')\n        plt.legend()\n        plt.show()\n    \n    else:\n        plt.plot(epochs,loss_per_epoch,label = 'training loss')\n        plt.grid()\n        plt.title('Training loss when overfitting with a Batch')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss Value')\n        plt.show()\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:31.61371Z","iopub.execute_input":"2022-02-20T19:47:31.614444Z","iopub.status.idle":"2022-02-20T19:47:31.622376Z","shell.execute_reply.started":"2022-02-20T19:47:31.614399Z","shell.execute_reply":"2022-02-20T19:47:31.621524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Αξιολόγηση του μοντέλου","metadata":{}},{"cell_type":"code","source":"def test_model(test_loader,filename):\n    model = pickle.load(open(filename, 'rb'))\n    model.eval()\n    test_acc = 0\n    predictions = []\n    labels = []\n    with torch.no_grad():\n        for (i,data) in enumerate(test_loader):\n            X_batch, y_batch, len_batch = data # get the features and labels\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            len_batch = len_batch.to(device)\n            \n            out = model(X_batch,len_batch).double()\n            val,y_pred = out.max(1)\n            \n            for pred in y_pred:\n                predictions.append(pred.item())\n            for lab in y_batch:\n                labels.append(lab.item())\n                \n    print(classification_report(labels,predictions))\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:34.667271Z","iopub.execute_input":"2022-02-20T19:47:34.667791Z","iopub.status.idle":"2022-02-20T19:47:34.675274Z","shell.execute_reply.started":"2022-02-20T19:47:34.667749Z","shell.execute_reply":"2022-02-20T19:47:34.674384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:39.613684Z","iopub.execute_input":"2022-02-20T19:47:39.614552Z","iopub.status.idle":"2022-02-20T19:47:39.674514Z","shell.execute_reply.started":"2022-02-20T19:47:39.614505Z","shell.execute_reply":"2022-02-20T19:47:39.672697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sp = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms\",\n        class_mapping = CLASS_MAPPING, train = True, option = 'sp_only')\ntrain_sp , val_sp = torch_train_val_split(sp, 32, 32, val_size=.3)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T15:49:41.896831Z","iopub.execute_input":"2022-02-20T15:49:41.897683Z","iopub.status.idle":"2022-02-20T15:49:46.422649Z","shell.execute_reply.started":"2022-02-20T15:49:41.897639Z","shell.execute_reply":"2022-02-20T15:49:46.421751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batch Overfit","metadata":{}},{"cell_type":"code","source":"tr_loss,val_loss = train_lstm(train_sp,val_sp,input_size = 128,output_dim = 10, lf = 1,\n                              filename='lstm_sp.sav',overfit_batch = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(tr_loss,val_loss,overfit_batch=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T20:33:12.387134Z","iopub.execute_input":"2022-02-18T20:33:12.387784Z","iopub.status.idle":"2022-02-18T20:33:12.56853Z","shell.execute_reply.started":"2022-02-18T20:33:12.387748Z","shell.execute_reply":"2022-02-18T20:33:12.567851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση με το Φασματογράφημα","metadata":{}},{"cell_type":"code","source":"tr_loss,val_loss = train_lstm(train_sp,val_sp,input_size = 128, output_dim = 10, lf = 1,\n                              filename='lstm_sp.sav',overfit_batch= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(tr_loss,val_loss,overfit_batch=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:18:17.942455Z","iopub.execute_input":"2022-02-20T16:18:17.942738Z","iopub.status.idle":"2022-02-20T16:18:18.252661Z","shell.execute_reply.started":"2022-02-20T16:18:17.942705Z","shell.execute_reply":"2022-02-20T16:18:18.251919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sp_test = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/\",\n        class_mapping=CLASS_MAPPING, train = False ,option = 'sp_only')\n\nsp_test_loader = DataLoader(sp_test,batch_size = 20 , shuffle = True )","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:18:43.099872Z","iopub.execute_input":"2022-02-20T16:18:43.100795Z","iopub.status.idle":"2022-02-20T16:18:55.863611Z","shell.execute_reply.started":"2022-02-20T16:18:43.100749Z","shell.execute_reply":"2022-02-20T16:18:55.862791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(sp_test_loader,filename = 'lstm_sp.sav')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:19:11.446429Z","iopub.execute_input":"2022-02-20T16:19:11.446719Z","iopub.status.idle":"2022-02-20T16:19:17.153284Z","shell.execute_reply.started":"2022-02-20T16:19:11.446685Z","shell.execute_reply":"2022-02-20T16:19:17.151657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση για το Beat Synced Spectograms","metadata":{}},{"cell_type":"code","source":"bssp = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat\",\n        class_mapping=CLASS_MAPPING, train=True, option = 'sp_only')\ntrain_bssp , val_bssp = torch_train_val_split(bssp, 32, 32, val_size=.3)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:46:05.193405Z","iopub.execute_input":"2022-02-20T16:46:05.19372Z","iopub.status.idle":"2022-02-20T16:46:17.690642Z","shell.execute_reply.started":"2022-02-20T16:46:05.193688Z","shell.execute_reply":"2022-02-20T16:46:17.689916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bssp_tr_loss,bssp_val_loss = train_lstm(train_bssp,val_bssp,input_size = 128,output_dim = 10, lf = 1,\n                                        filename = 'lstm_bssp.sav',overfit_batch=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(bssp_tr_loss,bssp_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:49:04.084961Z","iopub.execute_input":"2022-02-20T16:49:04.085494Z","iopub.status.idle":"2022-02-20T16:49:04.288494Z","shell.execute_reply.started":"2022-02-20T16:49:04.085457Z","shell.execute_reply":"2022-02-20T16:49:04.287839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bssp_test = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat\",\n        class_mapping=CLASS_MAPPING, train = False ,option = 'sp_only')\n\nbssp_test_loader = DataLoader(bssp_test, batch_size = 20 , shuffle = True )","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:31.129068Z","iopub.execute_input":"2022-02-20T16:50:31.129493Z","iopub.status.idle":"2022-02-20T16:50:34.00448Z","shell.execute_reply.started":"2022-02-20T16:50:31.129447Z","shell.execute_reply":"2022-02-20T16:50:34.003785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(sp_test_loader,filename = 'lstm_bssp.sav')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eκπαίδευση για τα Χρωμογραφήματα","metadata":{}},{"cell_type":"code","source":"chr_data = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms\",\n        class_mapping=CLASS_MAPPING, train = True, option = 'chr_only')\n\ntrain_chr , val_chr = torch_train_val_split(chr_data, 32, 32, val_size=.3)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:36:41.903294Z","iopub.execute_input":"2022-02-20T17:36:41.903594Z","iopub.status.idle":"2022-02-20T17:36:46.489134Z","shell.execute_reply.started":"2022-02-20T17:36:41.90356Z","shell.execute_reply":"2022-02-20T17:36:46.488335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chr_tr_loss, chr_val_loss = train_lstm(train_chr , val_chr , input_size = 12, output_dim = 10, \n                                       lf = 1, filename = 'lstm_chr.sav' ,overfit_batch=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(chr_tr_loss,chr_val_loss,overfit_batch=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:00:14.47005Z","iopub.execute_input":"2022-02-20T18:00:14.470673Z","iopub.status.idle":"2022-02-20T18:00:14.698678Z","shell.execute_reply.started":"2022-02-20T18:00:14.470634Z","shell.execute_reply":"2022-02-20T18:00:14.697896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(chr_val_loss[-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:02:40.127916Z","iopub.execute_input":"2022-02-20T18:02:40.12861Z","iopub.status.idle":"2022-02-20T18:02:40.133422Z","shell.execute_reply.started":"2022-02-20T18:02:40.128573Z","shell.execute_reply":"2022-02-20T18:02:40.132437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chr_test = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms\",\n        class_mapping=CLASS_MAPPING, train = False, option = 'chr_only')\n\nchr_test_loader = DataLoader(chr_test,batch_size = 20 , shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:00:18.400747Z","iopub.execute_input":"2022-02-20T18:00:18.401397Z","iopub.status.idle":"2022-02-20T18:00:29.268174Z","shell.execute_reply.started":"2022-02-20T18:00:18.401355Z","shell.execute_reply":"2022-02-20T18:00:29.267378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(chr_test_loader,filename = 'lstm_chr.sav')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:02:54.520343Z","iopub.execute_input":"2022-02-20T18:02:54.520685Z","iopub.status.idle":"2022-02-20T18:02:59.381084Z","shell.execute_reply.started":"2022-02-20T18:02:54.520651Z","shell.execute_reply":"2022-02-20T18:02:59.3802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση για τα ενωμένα Χρωμογραφήματα - Φασματογραφήματα","metadata":{}},{"cell_type":"code","source":"train_spch , val_spch =  torch_train_val_split(dataset, 32, 32, val_size=.3)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:06:06.289618Z","iopub.execute_input":"2022-02-20T18:06:06.289967Z","iopub.status.idle":"2022-02-20T18:06:06.295547Z","shell.execute_reply.started":"2022-02-20T18:06:06.289922Z","shell.execute_reply":"2022-02-20T18:06:06.294752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spch_tr_loss, spch_val_loss = train_lstm(train_spch,val_spch,input_size = 140,output_dim = 10,\n                                         lf = 1, filename = 'lstm_spch.sav', overfit_batch=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(spch_val_loss[-1])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:30:29.755314Z","iopub.execute_input":"2022-02-20T18:30:29.755627Z","iopub.status.idle":"2022-02-20T18:30:29.761481Z","shell.execute_reply.started":"2022-02-20T18:30:29.755582Z","shell.execute_reply":"2022-02-20T18:30:29.760282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(spch_tr_loss,spch_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:28:48.244838Z","iopub.execute_input":"2022-02-20T18:28:48.245591Z","iopub.status.idle":"2022-02-20T18:28:48.460478Z","shell.execute_reply.started":"2022-02-20T18:28:48.245554Z","shell.execute_reply":"2022-02-20T18:28:48.459709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spch_test = SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms\",\n        class_mapping=CLASS_MAPPING, train = False , option = 'both')\n\nspch_test_loader = DataLoader(spch_test, batch_size = 20 , shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:28:53.126209Z","iopub.execute_input":"2022-02-20T18:28:53.126498Z","iopub.status.idle":"2022-02-20T18:29:00.435717Z","shell.execute_reply.started":"2022-02-20T18:28:53.126464Z","shell.execute_reply":"2022-02-20T18:29:00.434901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(spch_test_loader,filename = 'lstm_spch.sav')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:29:28.607363Z","iopub.execute_input":"2022-02-20T18:29:28.608078Z","iopub.status.idle":"2022-02-20T18:29:34.652643Z","shell.execute_reply.started":"2022-02-20T18:29:28.608007Z","shell.execute_reply":"2022-02-20T18:29:34.651839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bήμα 7ο: CNN Model για ταξινόμηση του FMA","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN_model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.conv2 = nn.Conv2d(4, 8, 3)\n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16*159*14, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x, lengths):\n        x = torch.unsqueeze(x,1).double().to('cuda')\n        \n        x = self.conv1(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv2(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv3(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n\n        x = torch.flatten(x, 1).to('cuda') # flatten all dimensions except batch\n        x = F.relu(self.fc1(x)).to('cuda')\n        x = F.relu(self.fc2(x)).to('cuda')\n        x = self.fc3(x).to('cuda')\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:51.807631Z","iopub.execute_input":"2022-02-20T19:47:51.80794Z","iopub.status.idle":"2022-02-20T19:47:51.820627Z","shell.execute_reply.started":"2022-02-20T19:47:51.807902Z","shell.execute_reply":"2022-02-20T19:47:51.819763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_cnn(model,train_loader,val_loader,lf,filename,overfit_batch=False):\n    patience = 10\n    learning_rate = 1e-4  \n    \n    if(lf == 1):\n        criterion = nn.CrossEntropyLoss()\n    \n    elif (lf == 0):\n        criterion = nn.MSELoss()\n        \n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    loss_per_epoch = []\n    val_loss_per_epoch = []\n    \n    model.train()\n    model = model.double()\n    \n    if(overfit_batch == False):\n        EPOCHS = 50\n        for epoch in range(EPOCHS):\n            val_loss = 0\n            for (i,data) in enumerate(val_loader):\n            \n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n                out = model(X_batch,len_batch).double() # forward pass\n                \n                if(lf == 0 ):\n                    new_shape = (len(y_batch), 1)\n                    y_batch = y_batch.view(new_shape)\n                \n                loss = criterion(out, y_batch) # compute per batch loss \n                val_loss +=loss.detach().item()\n                \n            val_loss_per_epoch.append(val_loss/i)\n            i = np.argmin(val_loss_per_epoch)\n            if (i == epoch):\n                best_model = model     \n            if (epoch > i + patience):\n                val_loss_per_epoch.pop(-1)\n                print('Early stopping...')\n                break\n            \n            running_average_loss = 0\n            for (i,data) in enumerate(train_loader):\n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n            \n                optimizer.zero_grad() # ALWAYS USE THIS!! \n                out = model(X_batch,len_batch).double() # forward pass\n                \n                if(lf == 0 ):\n                    new_shape = (len(y_batch), 1)\n                    y_batch = y_batch.view(new_shape)\n                    \n                loss = criterion(out, y_batch) # compute per batch loss \n                loss.backward() # compure gradients based on the loss function\n                optimizer.step() # update weights \n                l = loss.detach().item()\n                running_average_loss += l\n                if i % 10 == 0:\n                    print(\"Epoch: {} \\t Batch: {} \\t Loss {}\".format(epoch, i,\n                                        float(l)))\n                \n            running_average_loss = running_average_loss/(i+1)\n            loss_per_epoch.append(running_average_loss)\n    \n    elif (overfit_batch == True):\n        EPOCHS = 750\n        X_batch , y_batch , len_batch = next(iter(train_loader))\n        for epoch in range(EPOCHS):\n            running_average_loss = 0\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            len_batch = len_batch.to(device)\n            \n            optimizer.zero_grad() # ALWAYS USE THIS!! \n            out = model(X_batch,len_batch).double() # forward pass\n            loss = criterion(out, y_batch) # compute per batch loss \n            loss.backward() # compure gradients based on the loss function\n            optimizer.step() # update weights \n            l = loss.detach().item()\n            running_average_loss += l\n            print(\"Epoch: {} \\t Loss {}\".format(epoch,\n                                      float(l)))\n                \n            running_average_loss = running_average_loss\n            loss_per_epoch.append(running_average_loss)\n            \n    pickle.dump(best_model, open(filename, 'wb'))  \n    \n    return loss_per_epoch,val_loss_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:47:58.026318Z","iopub.execute_input":"2022-02-20T19:47:58.026985Z","iopub.status.idle":"2022-02-20T19:47:58.048988Z","shell.execute_reply.started":"2022-02-20T19:47:58.026945Z","shell.execute_reply":"2022-02-20T19:47:58.048172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overfit Batch με το CNN","metadata":{}},{"cell_type":"code","source":"model = CNN_model().to(device)\n\ntr_loss,val_loss = train_cnn(model,train_sp,val_sp, lf = 1 ,\n                             filename='cnn_sp.sav',overfit_batch = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(tr_loss,val_loss,overfit_batch = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση του CNN με τα φασματογραφήματα","metadata":{}},{"cell_type":"code","source":"model = CNN_model().to(device)\ntrc_loss,valc_loss = train_cnn(model,train_sp,val_sp, lf = 1,\n                            filename='cnn_sp.sav',overfit_batch = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(trc_loss,valc_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:38:00.209031Z","iopub.execute_input":"2022-02-20T16:38:00.209706Z","iopub.status.idle":"2022-02-20T16:38:00.415331Z","shell.execute_reply.started":"2022-02-20T16:38:00.209666Z","shell.execute_reply":"2022-02-20T16:38:00.414668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(sp_test_loader,filename = 'cnn_sp.sav')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:43:36.612681Z","iopub.execute_input":"2022-02-20T16:43:36.612959Z","iopub.status.idle":"2022-02-20T16:43:37.895769Z","shell.execute_reply.started":"2022-02-20T16:43:36.612926Z","shell.execute_reply":"2022-02-20T16:43:37.895038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Εκπαίδευση για τα ενωμένα Χρωμογραφήματα - Φασματογραφήματα","metadata":{}},{"cell_type":"code","source":"model = CNN_model().to(device)\nspch_tr_loss, spch_val_loss = train_cnn(model,train_spch,val_spch, lf = 1,\n                            filename = 'cnn_spch.sav',overfit_batch = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(spch_tr_loss, spch_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:44:02.832222Z","iopub.execute_input":"2022-02-20T18:44:02.833174Z","iopub.status.idle":"2022-02-20T18:44:03.17561Z","shell.execute_reply.started":"2022-02-20T18:44:02.833135Z","shell.execute_reply":"2022-02-20T18:44:03.174739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model(spch_test_loader,filename = 'cnn_spch.sav')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:44:06.388391Z","iopub.execute_input":"2022-02-20T18:44:06.388994Z","iopub.status.idle":"2022-02-20T18:44:07.77248Z","shell.execute_reply.started":"2022-02-20T18:44:06.388956Z","shell.execute_reply":"2022-02-20T18:44:07.771595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 8ο : Εκτίμηση συναισθήματος με παλινδρόμηση","metadata":{}},{"cell_type":"code","source":"valence_labels = []\nenergy_labels = []\ndanceability_labels = []\nids = []\n\npath = \"../input/patreco3-multitask-affective-music/data/multitask_dataset/train_labels.txt\"\n\nwith open(path) as f:\n    files = f.readlines()\n    \nfiles.pop(0)\n\ndataset = []\nfor i in range(len(files)):\n    dataset.append(files[i].split(','))\n    dataset[i][0] = int(dataset[i][0])\n    dataset[i][1] = float(dataset[i][1])\n    dataset[i][2] = float(dataset[i][2])\n    dataset[i][3] = float(dataset[i][3][:-1])\n    \nfor i in range(len(dataset)):\n    ids.append(dataset[i][0])\n    valence_labels.append(dataset[i][1])\n    energy_labels.append(dataset[i][2])\n    danceability_labels.append(dataset[i][3])\n    \nids = np.array(ids)\nvalence_labels = np.array(valence_labels)\nenergy_labels = np.array(energy_labels)\ndanceability_labels = np.array(danceability_labels)\n\nspectrogram_file = \"../input/patreco3-multitask-affective-music/data/multitask_dataset/train/\"\nf = os.listdir(spectrogram_file)\nzeros = np.zeros((140, 1))\nspecs = []\nfor i in range(len(f)):\n    spec = np.load(spectrogram_file + f[i])\n    id1 = int(f[i].split('.')[0])\n    original_shape = spec.shape[1]\n    if spec.shape[1] != 1293:\n        while(spec.shape[1] < 1293):\n            spec = np.concatenate((spec, zeros), axis=1)\n    specs.append([spec.T, id1, original_shape])\n    \nspecs_valence = []\nspecs_energy = []\nspecs_danceability = []\nspecs_multi=[]\n\nfor i in range(len(ids)):\n    for spec in specs:\n        if spec[1] == ids[i]:\n            specs_valence.append(spec)\n            specs_valence[-1][1] = valence_labels[i]\n            specs_energy.append(spec)\n            specs_energy[-1][1] = energy_labels[i]\n            specs_danceability.append(spec)\n            specs_danceability[-1][1] = danceability_labels[i]\n            specs_multi.append(spec)\n           # specs_multi[-1][1]= (valence_labels[i],energy_labels[i],danceability_labels[i])\n            break","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:53:47.865155Z","iopub.execute_input":"2022-02-20T18:53:47.865645Z","iopub.status.idle":"2022-02-20T18:54:14.312191Z","shell.execute_reply.started":"2022-02-20T18:53:47.865606Z","shell.execute_reply":"2022-02-20T18:54:14.310622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN δίκτυο για παλινδρόμηση (Regression)","metadata":{}},{"cell_type":"code","source":"class CNN_model_regression(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.conv2 = nn.Conv2d(4, 8, 3)\n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 159 * 15, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 1)\n\n    def forward(self, x, lengths):\n        x = torch.unsqueeze(x,1).double().to('cuda')\n        \n        x = self.conv1(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv2(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv3(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n\n        x = torch.flatten(x, 1).to('cuda')# flatten all dimensions except batch\n        x = F.relu(self.fc1(x)).to('cuda')\n        x = F.relu(self.fc2(x)).to('cuda')\n        x = self.fc3(x).to('cuda')\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:48:06.837382Z","iopub.execute_input":"2022-02-20T19:48:06.838017Z","iopub.status.idle":"2022-02-20T19:48:06.852018Z","shell.execute_reply.started":"2022-02-20T19:48:06.837971Z","shell.execute_reply":"2022-02-20T19:48:06.851063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n\ndef model_eval_regression(val_loader,filename):\n    model = pickle.load(open(filename, 'rb'))\n    model.eval()\n    pred = []\n    true = []\n    total_preds = 0\n    with torch.no_grad(): \n        for i, data in enumerate(val_loader):\n            x_batch, y_batch,len_batch = data \n            total_preds += len(len_batch)\n            x_batch = x_batch.to('cuda')\n            y_batch = y_batch.to('cuda')\n            len_batch = len_batch.to('cuda')\n            out = model(x_batch,len_batch).double().to('cuda')\n            y_pred, val = out.max(1)\n            for j in range(len(y_pred)):\n                pred.append(y_pred[j])\n                true.append(y_batch[j])\n        \n    true = torch.Tensor(true)\n    pred = torch.Tensor(pred)\n    corr, pval = stats.spearmanr(true, pred)\n    return corr","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:48:09.610682Z","iopub.execute_input":"2022-02-20T19:48:09.611317Z","iopub.status.idle":"2022-02-20T19:48:09.619614Z","shell.execute_reply.started":"2022-02-20T19:48:09.611271Z","shell.execute_reply":"2022-02-20T19:48:09.618773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Valence","metadata":{}},{"cell_type":"code","source":"valence_train_loader,valence_val_loader = torch_train_val_split(specs_valence,\n                                                    32 ,32, val_size=.30)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:54:55.604965Z","iopub.execute_input":"2022-02-20T18:54:55.605583Z","iopub.status.idle":"2022-02-20T18:54:55.62154Z","shell.execute_reply.started":"2022-02-20T18:54:55.605541Z","shell.execute_reply":"2022-02-20T18:54:55.620661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"lstm_valence_tr_loss,lstm_valence_val_loss = train_lstm(valence_train_loader,valence_val_loader,\n                              input_size = 140, output_dim = 1, lf = 0 ,\n                              filename = 'lstm_valence.sav',overfit_batch= False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T18:55:01.298753Z","iopub.execute_input":"2022-02-20T18:55:01.299489Z","iopub.status.idle":"2022-02-20T19:05:14.84409Z","shell.execute_reply.started":"2022-02-20T18:55:01.299451Z","shell.execute_reply":"2022-02-20T19:05:14.843212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(lstm_valence_tr_loss,lstm_valence_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:05:35.074806Z","iopub.execute_input":"2022-02-20T19:05:35.075536Z","iopub.status.idle":"2022-02-20T19:05:35.321428Z","shell.execute_reply.started":"2022-02-20T19:05:35.075497Z","shell.execute_reply":"2022-02-20T19:05:35.320726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(valence_val_loader,filename = 'lstm_valence.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:05:38.12773Z","iopub.execute_input":"2022-02-20T19:05:38.129096Z","iopub.status.idle":"2022-02-20T19:05:40.80112Z","shell.execute_reply.started":"2022-02-20T19:05:38.129039Z","shell.execute_reply":"2022-02-20T19:05:40.800294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"cnn_regr = CNN_model_regression().to('cuda')\n\ncnn_valence_tr_loss,cnn_valence_val_loss = train_cnn(cnn_regr,valence_train_loader,\n                                                     valence_val_loader, lf = 0,\n                                                     filename='cnn_valence.sav',overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:09:42.257521Z","iopub.execute_input":"2022-02-20T19:09:42.257869Z","iopub.status.idle":"2022-02-20T19:11:12.56964Z","shell.execute_reply.started":"2022-02-20T19:09:42.25782Z","shell.execute_reply":"2022-02-20T19:11:12.568728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(cnn_valence_tr_loss,cnn_valence_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:11:44.867846Z","iopub.execute_input":"2022-02-20T19:11:44.868484Z","iopub.status.idle":"2022-02-20T19:11:45.106684Z","shell.execute_reply.started":"2022-02-20T19:11:44.868452Z","shell.execute_reply":"2022-02-20T19:11:45.105708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(valence_val_loader,filename = 'cnn_valence.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:11:47.94305Z","iopub.execute_input":"2022-02-20T19:11:47.943632Z","iopub.status.idle":"2022-02-20T19:11:48.969027Z","shell.execute_reply.started":"2022-02-20T19:11:47.943594Z","shell.execute_reply":"2022-02-20T19:11:48.96824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Energy","metadata":{}},{"cell_type":"code","source":"energy_train_loader, energy_val_loader = torch_train_val_split(specs_energy,\n                                                    32 ,32, val_size=.33)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:13:19.543853Z","iopub.execute_input":"2022-02-20T19:13:19.544227Z","iopub.status.idle":"2022-02-20T19:13:19.550877Z","shell.execute_reply.started":"2022-02-20T19:13:19.544192Z","shell.execute_reply":"2022-02-20T19:13:19.550144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"lstm_energy_tr_loss, lstm_energy_val_loss = train_lstm(energy_train_loader,energy_val_loader,\n                              input_size = 140, output_dim = 1, lf = 0,\n                              filename = 'lstm_energy.sav',overfit_batch= False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:13:27.271763Z","iopub.execute_input":"2022-02-20T19:13:27.27242Z","iopub.status.idle":"2022-02-20T19:20:11.294587Z","shell.execute_reply.started":"2022-02-20T19:13:27.272381Z","shell.execute_reply":"2022-02-20T19:20:11.293825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(lstm_energy_tr_loss, lstm_energy_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:20:26.519751Z","iopub.execute_input":"2022-02-20T19:20:26.520384Z","iopub.status.idle":"2022-02-20T19:20:26.717379Z","shell.execute_reply.started":"2022-02-20T19:20:26.520343Z","shell.execute_reply":"2022-02-20T19:20:26.716619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(energy_val_loader,filename = 'lstm_energy.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:20:29.513146Z","iopub.execute_input":"2022-02-20T19:20:29.513685Z","iopub.status.idle":"2022-02-20T19:20:32.325911Z","shell.execute_reply.started":"2022-02-20T19:20:29.513645Z","shell.execute_reply":"2022-02-20T19:20:32.325038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"cnn_regr = CNN_model_regression().to('cuda')\n\ncnn_energy_tr_loss, cnn_energy_val_loss = train_cnn(cnn_regr,energy_train_loader,\n                                                     energy_val_loader, lf = 0,\n                                                 filename = 'cnn_energy.sav',overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:21:37.553975Z","iopub.execute_input":"2022-02-20T19:21:37.554719Z","iopub.status.idle":"2022-02-20T19:23:25.964181Z","shell.execute_reply.started":"2022-02-20T19:21:37.554677Z","shell.execute_reply":"2022-02-20T19:23:25.963398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(cnn_energy_tr_loss, cnn_energy_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:23:29.610224Z","iopub.execute_input":"2022-02-20T19:23:29.61081Z","iopub.status.idle":"2022-02-20T19:23:29.807433Z","shell.execute_reply.started":"2022-02-20T19:23:29.61076Z","shell.execute_reply":"2022-02-20T19:23:29.806721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(energy_val_loader,filename = 'cnn_energy.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:23:32.900744Z","iopub.execute_input":"2022-02-20T19:23:32.901408Z","iopub.status.idle":"2022-02-20T19:23:34.031814Z","shell.execute_reply.started":"2022-02-20T19:23:32.901366Z","shell.execute_reply":"2022-02-20T19:23:34.030968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Danceability","metadata":{}},{"cell_type":"code","source":"dance_train_loader, dance_val_loader = torch_train_val_split(specs_danceability,\n                                                    32 ,32, val_size=.33)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:24:35.712917Z","iopub.execute_input":"2022-02-20T19:24:35.713204Z","iopub.status.idle":"2022-02-20T19:24:35.720141Z","shell.execute_reply.started":"2022-02-20T19:24:35.713175Z","shell.execute_reply":"2022-02-20T19:24:35.719309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"lstm_dance_tr_loss, lstm_dance_val_loss = train_lstm(dance_train_loader,dance_val_loader,\n                              input_size = 140, output_dim = 1, lf = 0,\n                              filename = 'lstm_dance.sav',overfit_batch= False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:24:42.455691Z","iopub.execute_input":"2022-02-20T19:24:42.456001Z","iopub.status.idle":"2022-02-20T19:30:54.333669Z","shell.execute_reply.started":"2022-02-20T19:24:42.455967Z","shell.execute_reply":"2022-02-20T19:30:54.332799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(lstm_dance_tr_loss, lstm_dance_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:31:19.051365Z","iopub.execute_input":"2022-02-20T19:31:19.052179Z","iopub.status.idle":"2022-02-20T19:31:19.255615Z","shell.execute_reply.started":"2022-02-20T19:31:19.052132Z","shell.execute_reply":"2022-02-20T19:31:19.254774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(dance_val_loader,filename = 'lstm_dance.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:31:22.022626Z","iopub.execute_input":"2022-02-20T19:31:22.023492Z","iopub.status.idle":"2022-02-20T19:31:24.817466Z","shell.execute_reply.started":"2022-02-20T19:31:22.023429Z","shell.execute_reply":"2022-02-20T19:31:24.816624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"cnn_regr = CNN_model_regression().to('cuda')\n\ncnn_dance_tr_loss, cnn_dance_val_loss = train_cnn(cnn_regr,dance_train_loader,\n                                                     dance_val_loader, lf = 0,\n                                                 filename = 'cnn_dance.sav',overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:32:04.688211Z","iopub.execute_input":"2022-02-20T19:32:04.688519Z","iopub.status.idle":"2022-02-20T19:34:38.659044Z","shell.execute_reply.started":"2022-02-20T19:32:04.688485Z","shell.execute_reply":"2022-02-20T19:34:38.657517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(cnn_dance_tr_loss, cnn_dance_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:34:42.102428Z","iopub.execute_input":"2022-02-20T19:34:42.102961Z","iopub.status.idle":"2022-02-20T19:34:42.314353Z","shell.execute_reply.started":"2022-02-20T19:34:42.102918Z","shell.execute_reply":"2022-02-20T19:34:42.313677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = model_eval_regression(dance_val_loader,filename = 'cnn_dance.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:34:45.068699Z","iopub.execute_input":"2022-02-20T19:34:45.069571Z","iopub.status.idle":"2022-02-20T19:34:46.217373Z","shell.execute_reply.started":"2022-02-20T19:34:45.06953Z","shell.execute_reply":"2022-02-20T19:34:46.215676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 9ο : Transfer Learning","metadata":{}},{"cell_type":"code","source":"class CNN_for_Transfer_Learning(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.conv2 = nn.Conv2d(4, 8, 3)\n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 159 * 15, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n \n\n    def forward(self, x, lengths):\n        x = torch.unsqueeze(x,1).double().to('cuda')\n        \n        x = self.conv1(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv2(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv3(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n\n \n\n        x = torch.flatten(x, 1).to('cuda') # flatten all dimensions except batch\n        x = F.relu(self.fc1(x)).to('cuda')\n        x = F.relu(self.fc2(x)).to('cuda')\n        x = self.fc3(x).to('cuda')\n        \n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training CNN on FMA dataset","metadata":{}},{"cell_type":"code","source":"cnn = CNN_for_Transfer_Learning().to(device)\n\n \n\ntr_loss,val_loss = train_cnn(cnn,train_spch,val_spch, lf = 1 ,\n                             filename='cnn_valence.sav',overfit_batch = False)\n\n \n\nplot_loss(tr_loss,val_loss,overfit_batch = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model and Retraining it in the new dataset","metadata":{}},{"cell_type":"code","source":"cnn = pickle.load(open('cnn_valence.sav', 'rb'))\ncnn.fc3 = nn.Linear(84, 1)\ncnn = cnn.to('cuda')\nspch_tr_loss,spch_val_loss = train_cnn(cnn,valence_train_loader,valence_val_loader, lf = 0 ,\n                             filename='cnn_valence.sav',overfit_batch = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(spch_tr_loss, spch_val_loss,overfit_batch = False)\ncorr = model_eval_regression(valence_val_loader,filename = 'cnn_valence.sav')\nprint('Spearman Correlation -> {}'.format(corr))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Βήμα 10ο: Εκπαίδευση σε Πολλαπλά Προβλήματα","metadata":{}},{"cell_type":"markdown","source":"# CNN Network for Multitask Learning","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN_multitask(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.conv2 = nn.Conv2d(4, 8, 3)\n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(16 * 159 * 14, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 3)\n\n    def forward(self, x, lengths):\n        x = torch.unsqueeze(x,1).double().to('cuda')\n        \n        x = self.conv1(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv2(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n        \n        x = self.conv3(x).to('cuda')\n        batch_norm = nn.BatchNorm2d(x.shape[1]).double().to('cuda')\n        x = self.pool(F.relu(batch_norm(x))).to('cuda')\n\n        x = torch.flatten(x, 1).to('cuda') # flatten all dimensions except batch\n        x = F.relu(self.fc1(x)).to('cuda')\n        x = F.relu(self.fc2(x)).to('cuda')\n        x = self.fc3(x).to('cuda')\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:48:30.827633Z","iopub.execute_input":"2022-02-20T19:48:30.828644Z","iopub.status.idle":"2022-02-20T19:48:30.843792Z","shell.execute_reply.started":"2022-02-20T19:48:30.828599Z","shell.execute_reply":"2022-02-20T19:48:30.842924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Multilabel_SpectrogramDataset(Dataset):\n    def __init__(self, path, option, class_mapping, \n                 train=True, max_length=-1, regression = None):\n        \n        t = \"train\" if train else \"test\"\n        p = os.path.join(path, t)\n        self.regression = regression\n\n        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n        self.files, labels = self.get_files_multi_labels(self.index)\n        self.feats = [read_spectrogram(os.path.join(p, f),option) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n        self.label_transformer = LabelTransformer()\n        \n        if isinstance(labels, (list, tuple)):\n            self.labels = np.array(labels).astype(\"float64\")\n\n    def get_files_multi_labels(self, txt):\n        # Returns a list of file names and a list of their labels\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]\n            \n        files, labels = [], []\n        for l in lines:\n            label = (float(l[1]),float(l[2]),float(l[3]))\n            labels.append(label)\n            # Kaggle automatically unzips the npy.gz format so this hack is needed\n            _id = int(l[0])\n            npy_file = '{}.fused.full.npy'.format(_id)\n            files.append(npy_file)\n            \n        return files, labels\n\n    def __getitem__(self, item):\n        length = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:48:34.185687Z","iopub.execute_input":"2022-02-20T19:48:34.186579Z","iopub.status.idle":"2022-02-20T19:48:34.201209Z","shell.execute_reply.started":"2022-02-20T19:48:34.186537Z","shell.execute_reply":"2022-02-20T19:48:34.200335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_specs = Multilabel_SpectrogramDataset(\n        \"../input/patreco3-multitask-affective-music/data/multitask_dataset\",\n        class_mapping = None , train = True , option = 'sp_only')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:48:38.347101Z","iopub.execute_input":"2022-02-20T19:48:38.347694Z","iopub.status.idle":"2022-02-20T19:48:58.42834Z","shell.execute_reply.started":"2022-02-20T19:48:38.347652Z","shell.execute_reply":"2022-02-20T19:48:58.427512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_train_loader, multi_val_loader = torch_train_val_split(multi_specs,\n                                                    32 ,32, val_size=.33)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:49:11.535983Z","iopub.execute_input":"2022-02-20T19:49:11.536687Z","iopub.status.idle":"2022-02-20T19:49:11.542926Z","shell.execute_reply.started":"2022-02-20T19:49:11.536642Z","shell.execute_reply":"2022-02-20T19:49:11.541674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function For Multitask Learning","metadata":{}},{"cell_type":"code","source":"class L1loss(nn.Module):\n    def __init__(self, weights):\n        super(L1loss, self).__init__()\n        self.w = weights.to(device)\n    \n    def forward(self,inputs,targets):\n        l1loss = torch.zeros(inputs.shape[0]).to(device)\n        \n        for i in range(inputs.shape[0]):\n            for j in range(inputs.shape[1]):\n                a = abs(inputs[i][j] - targets[i][j])\n                l1loss[i] += self.w[j]*a\n          \n        return torch.mean(l1loss)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:50:07.972357Z","iopub.execute_input":"2022-02-20T19:50:07.972935Z","iopub.status.idle":"2022-02-20T19:50:07.979962Z","shell.execute_reply.started":"2022-02-20T19:50:07.972893Z","shell.execute_reply":"2022-02-20T19:50:07.979202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_multi_cnn(model,train_loader,val_loader,filename,overfit_batch=False):\n    patience = 10\n    learning_rate = 1e-4  \n\n    weights = torch.Tensor([1,1,1]).to(device)\n    criterion = L1loss (weights).to(device)\n    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n    loss_per_epoch = []\n    val_loss_per_epoch = []\n    \n    model.train()\n    model = model.double()\n    \n    if(overfit_batch == False):\n        EPOCHS = 20\n        for epoch in range(EPOCHS):\n            val_loss = 0\n            for (i,data) in enumerate(val_loader):\n            \n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n                out = model(X_batch,len_batch).double() # forward pass\n                \n                loss = criterion(out, y_batch) # compute per batch loss \n                val_loss +=loss.detach().item()\n        \n            val_loss_per_epoch.append(val_loss/i)\n            \n            i = np.argmin(val_loss_per_epoch)\n            if (i == epoch):\n                best_model = model     \n            if (epoch > i + patience):\n                val_loss_per_epoch.pop(-1)\n                print('Early stopping...')\n                break\n            \n            running_average_loss = 0\n            for (i,data) in enumerate(train_loader):\n                X_batch, y_batch, len_batch = data # get the features and labels\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                len_batch = len_batch.to(device)\n            \n                optimizer.zero_grad() # ALWAYS USE THIS!! \n                out = model(X_batch,len_batch).double() # forward pass\n                    \n                loss = criterion(out, y_batch) # compute per batch loss \n                loss.backward() # compure gradients based on the loss function\n                optimizer.step() # update weights \n                l = loss.detach().item()\n                running_average_loss += l\n                if i % 10 == 0:\n                    print(\"Epoch: {} \\t Batch: {} \\t Loss {}\".format(epoch, i,\n                                        float(l)))\n                \n            running_average_loss = running_average_loss/(i+1)\n            loss_per_epoch.append(running_average_loss)\n    \n    elif (overfit_batch == True):\n        EPOCHS = 750\n        X_batch , y_batch , len_batch = next(iter(train_loader))\n        for epoch in range(EPOCHS):\n            running_average_loss = 0\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            len_batch = len_batch.to(device)\n            \n            optimizer.zero_grad() # ALWAYS USE THIS!! \n            out = model(X_batch,len_batch).double() # forward pass\n            loss = criterion(out, y_batch) # compute per batch loss \n            loss.backward() # compure gradients based on the loss function\n            optimizer.step() # update weights \n            l = loss.detach().item()\n            running_average_loss += l\n            print(\"Epoch: {} \\t Loss {}\".format(epoch,\n                                      float(l)))\n                \n            running_average_loss = running_average_loss\n            loss_per_epoch.append(running_average_loss)\n            \n    pickle.dump(best_model, open(filename, 'wb'))  \n    \n    return loss_per_epoch,val_loss_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:51:36.886697Z","iopub.execute_input":"2022-02-20T19:51:36.887083Z","iopub.status.idle":"2022-02-20T19:51:36.905515Z","shell.execute_reply.started":"2022-02-20T19:51:36.887041Z","shell.execute_reply":"2022-02-20T19:51:36.904678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_mult = CNN_multitask().to('cuda')\n\ncnn_mult_tr_loss, cnn_mult_val_loss = train_multi_cnn(cnn_mult,multi_train_loader, multi_val_loader,\n                                                 filename = 'cnn_mult.sav',overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:51:40.386685Z","iopub.execute_input":"2022-02-20T19:51:40.387504Z","iopub.status.idle":"2022-02-20T19:53:28.027545Z","shell.execute_reply.started":"2022-02-20T19:51:40.387462Z","shell.execute_reply":"2022-02-20T19:53:28.026721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(cnn_mult_tr_loss,cnn_mult_val_loss,overfit_batch = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:54:26.236067Z","iopub.execute_input":"2022-02-20T19:54:26.236718Z","iopub.status.idle":"2022-02-20T19:54:26.48647Z","shell.execute_reply.started":"2022-02-20T19:54:26.236675Z","shell.execute_reply":"2022-02-20T19:54:26.485755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_eval_multi_regression(val_loader,filename):\n    model = pickle.load(open(filename, 'rb'))\n    model.eval()\n    pred_valence = []\n    true_valence = []\n    pred_energy = []\n    true_energy =[]\n    pred_dance = []\n    true_dance = []\n    \n    total_preds = 0\n    with torch.no_grad(): \n        for i, data in enumerate(val_loader):\n            x_batch, y_batch,len_batch = data \n            total_preds += len(len_batch)\n            x_batch = x_batch.to('cuda')\n            y_batch = y_batch.to('cuda')\n            len_batch = len_batch.to('cuda')\n            out = model(x_batch,len_batch).double().to('cuda')\n            for j in range(len(out)):\n                pred_valence.append(out[j][0])\n                true_valence.append(y_batch[j][0])\n                pred_energy.append(out[j][1])\n                true_energy.append(y_batch[j][1])\n                pred_dance.append(out[j][2])\n                true_dance.append(y_batch[j][2])\n        \n    true_valence = torch.Tensor(true_valence)\n    pred_valence = torch.Tensor(pred_valence)\n    true_energy = torch.Tensor(true_energy)\n    pred_energy = torch.Tensor(pred_energy)\n    true_dance = torch.Tensor(true_dance)\n    pred_dance = torch.Tensor(pred_dance)\n    \n    corr1, pval1 = stats.spearmanr(true_valence, pred_valence)\n    corr2, pval2 = stats.spearmanr(true_energy, pred_energy)\n    corr3, pval3 = stats.spearmanr(true_dance, pred_dance)\n    \n    return corr1,corr2,corr3","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:54:30.555659Z","iopub.execute_input":"2022-02-20T19:54:30.556411Z","iopub.status.idle":"2022-02-20T19:54:30.567518Z","shell.execute_reply.started":"2022-02-20T19:54:30.556369Z","shell.execute_reply":"2022-02-20T19:54:30.566773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_v,corr_e,corr_d = model_eval_multi_regression(multi_val_loader,filename = 'cnn_mult.sav')\n\nprint('Spearman Correlation For Valence -> {}'.format(corr_v))\nprint('Spearman Correlation For Energy -> {}'.format(corr_e))\nprint('Spearman Correlation For Danceability -> {}'.format(corr_d))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T19:54:33.771788Z","iopub.execute_input":"2022-02-20T19:54:33.772644Z","iopub.status.idle":"2022-02-20T19:54:34.917431Z","shell.execute_reply.started":"2022-02-20T19:54:33.772593Z","shell.execute_reply":"2022-02-20T19:54:34.916579Z"},"trusted":true},"execution_count":null,"outputs":[]}]}